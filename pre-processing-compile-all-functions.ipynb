{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c69f69",
   "metadata": {
    "papermill": {
     "duration": 0.00302,
     "end_time": "2023-10-10T15:39:32.800022",
     "exception": false,
     "start_time": "2023-10-10T15:39:32.797002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# For pre-processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457b415",
   "metadata": {
    "papermill": {
     "duration": 0.003906,
     "end_time": "2023-10-10T15:39:32.806416",
     "exception": false,
     "start_time": "2023-10-10T15:39:32.802510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbdf45a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T15:39:32.813941Z",
     "iopub.status.busy": "2023-10-10T15:39:32.813219Z",
     "iopub.status.idle": "2023-10-10T15:39:35.471384Z",
     "shell.execute_reply": "2023-10-10T15:39:35.469944Z"
    },
    "papermill": {
     "duration": 2.665024,
     "end_time": "2023-10-10T15:39:35.474213",
     "exception": false,
     "start_time": "2023-10-10T15:39:32.809189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9153395e",
   "metadata": {
    "papermill": {
     "duration": 0.002371,
     "end_time": "2023-10-10T15:39:35.479443",
     "exception": false,
     "start_time": "2023-10-10T15:39:35.477072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# To map categorical variables to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b86d73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T15:39:35.487153Z",
     "iopub.status.busy": "2023-10-10T15:39:35.485834Z",
     "iopub.status.idle": "2023-10-10T15:39:35.531812Z",
     "shell.execute_reply": "2023-10-10T15:39:35.530963Z"
    },
    "papermill": {
     "duration": 0.052049,
     "end_time": "2023-10-10T15:39:35.534028",
     "exception": false,
     "start_time": "2023-10-10T15:39:35.481979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            died\n",
      "1      euthanized\n",
      "2           lived\n",
      "3            died\n",
      "4            died\n",
      "          ...    \n",
      "294    euthanized\n",
      "295    euthanized\n",
      "296          died\n",
      "297         lived\n",
      "298    euthanized\n",
      "Name: outcome, Length: 299, dtype: object\n",
      "0      0\n",
      "1      1\n",
      "2      2\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "294    1\n",
      "295    1\n",
      "296    0\n",
      "297    2\n",
      "298    1\n",
      "Name: outcome, Length: 299, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_horse_survival = pd.read_csv(\"/kaggle/input/horse-survival-dataset/horse.csv\")\n",
    "\n",
    "print(data_horse_survival[\"outcome\"])\n",
    "data_horse_survival[\"outcome\"] = data_horse_survival[\"outcome\"].map({'died':0,'euthanized':1,'lived':2})\n",
    "print(data_horse_survival[\"outcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd502f24",
   "metadata": {
    "papermill": {
     "duration": 0.002397,
     "end_time": "2023-10-10T15:39:35.539074",
     "exception": false,
     "start_time": "2023-10-10T15:39:35.536677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Piepeline for encoding and imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2473d12c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T15:39:35.546212Z",
     "iopub.status.busy": "2023-10-10T15:39:35.545747Z",
     "iopub.status.idle": "2023-10-10T15:39:36.235541Z",
     "shell.execute_reply": "2023-10-10T15:39:36.234328Z"
    },
    "papermill": {
     "duration": 0.696637,
     "end_time": "2023-10-10T15:39:36.238138",
     "exception": false,
     "start_time": "2023-10-10T15:39:35.541501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Write custom class to detect Cluster Similarity\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "class ClusterSimilarity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, n_init=10,  gamma=1.0, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        self.random_state = random_state\n",
    "        self.n_init = n_init\n",
    "    \n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.kmeans_ = KMeans(self.n_clusters, random_state=self.random_state, n_init=self.n_init)\n",
    "        self.kmeans_.fit(X,sample_weight=sample_weight)\n",
    "        return self #always return self\n",
    "    def transform(self, X):\n",
    "        return rbf_kernel(X, self.kmeans_.cluster_centers_, gamma=self.gamma)\n",
    "    \n",
    "    def get_feature_names_out(self, names=None):\n",
    "        return [f\"Cluster {i} similarity\"for i in range(self.n_clusters)]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#custom functions for ratio pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "def column_ratio(X):\n",
    "    return X[:,[0]]/(X[:,[1]]+1e-16)\n",
    "\n",
    "def ratio_name(function_transformer, feature_names_in):\n",
    "    return [\"ratio\"] #feature names out\n",
    "\n",
    "def ratio_pipeline():\n",
    "    return make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        FunctionTransformer(column_ratio, feature_names_out = ratio_name),\n",
    "        StandardScaler())\n",
    "\n",
    "#log pipeline \n",
    "\n",
    "log_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    FunctionTransformer(np.log, feature_names_out = \"one-to-one\"),\n",
    "    StandardScaler())\n",
    "\n",
    "#cluster_simil\n",
    "cluster_simil = ClusterSimilarity(n_clusters=10, n_init=10, gamma=1., random_state=42)\n",
    "\n",
    "default_num_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    StandardScaler())\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "preprocessing_complex = ColumnTransformer([\n",
    "    (\"FareByPclass\", ratio_pipeline(), [\"Fare\", \"Pclass\"]),\n",
    "    (\"AgeBySibSp\", ratio_pipeline(), [\"Age\",\"SibSp\"]),\n",
    "    (\"AgeByParch\", ratio_pipeline(), [\"Age\",\"Parch\"]),\n",
    "    (\"log\", log_pipeline, [\"Age\"]),\n",
    "    (\"geo\", cluster_simil, [\"Fare\"]),\n",
    "    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object)),\n",
    "    \n",
    "],\n",
    "remainder = default_num_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2bf00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T15:39:36.244777Z",
     "iopub.status.busy": "2023-10-10T15:39:36.244472Z",
     "iopub.status.idle": "2023-10-10T15:39:36.262122Z",
     "shell.execute_reply": "2023-10-10T15:39:36.261270Z"
    },
    "papermill": {
     "duration": 0.0235,
     "end_time": "2023-10-10T15:39:36.264314",
     "exception": false,
     "start_time": "2023-10-10T15:39:36.240814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"/kaggle/input/titanic-dataset/Titanic-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eaa45bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T15:39:36.271716Z",
     "iopub.status.busy": "2023-10-10T15:39:36.271097Z",
     "iopub.status.idle": "2023-10-10T15:39:36.499705Z",
     "shell.execute_reply": "2023-10-10T15:39:36.498389Z"
    },
    "papermill": {
     "duration": 0.234917,
     "end_time": "2023-10-10T15:39:36.501995",
     "exception": false,
     "start_time": "2023-10-10T15:39:36.267078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1740)\n",
      "['FareByPclass__ratio' 'AgeBySibSp__ratio' 'AgeByParch__ratio' ...\n",
      " 'cat__Embarked_S' 'remainder__PassengerId' 'remainder__Survived']\n",
      "[[-0.44184663 -1.200832   -0.10613411 ...  1.         -1.73010796\n",
      "  -0.78927234]\n",
      " [ 0.90276285 -1.200832    0.86439053 ...  0.         -1.72622007\n",
      "   1.2669898 ]\n",
      " [-0.43745355  0.2928375   0.13649705 ...  1.         -1.72233219\n",
      "   1.2669898 ]\n",
      " ...\n",
      " [-0.33641254 -1.200832   -1.44060549 ...  1.          1.72233219\n",
      "  -0.78927234]\n",
      " [ 0.09671333  0.2928375   0.13649705 ...  0.          1.72622007\n",
      "   1.2669898 ]\n",
      " [-0.4385925   0.63753046  0.50044379 ...  0.          1.73010796\n",
      "  -0.78927234]]\n"
     ]
    }
   ],
   "source": [
    "##note modify column names in the function as per your dataset\n",
    "\n",
    "# to transform and fit data\n",
    "train_inputs_processed = preprocessing_complex.fit_transform(titanic_data)\n",
    "\n",
    "#to just transform data\n",
    "train_inputs_processed = preprocessing_complex.transform(titanic_data)\n",
    "\n",
    "print(train_inputs_processed.shape)\n",
    "print(preprocessing_complex.get_feature_names_out())\n",
    "print(train_inputs_processed.toarray())\n",
    "#train_inputs_array = train_inputs_processed.toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.738553,
   "end_time": "2023-10-10T15:39:37.428615",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-10T15:39:29.690062",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
