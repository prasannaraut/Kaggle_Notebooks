{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-22T10:42:20.044263Z","iopub.execute_input":"2023-09-22T10:42:20.044732Z","iopub.status.idle":"2023-09-22T10:42:20.055924Z","shell.execute_reply.started":"2023-09-22T10:42:20.044696Z","shell.execute_reply":"2023-09-22T10:42:20.054060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This is a reference notebook to document regression model using Sklearn**","metadata":{}},{"cell_type":"code","source":"#import all required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_selector, make_column_transformer, ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, FunctionTransformer\nfrom sklearn.metrics.pairwise import rbf_kernel\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom pandas.plotting import scatter_matrix","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:20.068115Z","iopub.execute_input":"2023-09-22T10:42:20.068551Z","iopub.status.idle":"2023-09-22T10:42:20.075537Z","shell.execute_reply.started":"2023-09-22T10:42:20.068517Z","shell.execute_reply":"2023-09-22T10:42:20.074518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load dataset\nhousing = pd.read_csv(\"/kaggle/input/california-housing-prices/housing.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:20.094667Z","iopub.execute_input":"2023-09-22T10:42:20.095760Z","iopub.status.idle":"2023-09-22T10:42:20.143542Z","shell.execute_reply.started":"2023-09-22T10:42:20.095719Z","shell.execute_reply":"2023-09-22T10:42:20.142329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visuzlize the dataset**","metadata":{}},{"cell_type":"code","source":"#get the info of dataset\nprint(housing.info())\nprint(housing.describe())","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:20.149018Z","iopub.execute_input":"2023-09-22T10:42:20.149421Z","iopub.status.idle":"2023-09-22T10:42:20.204236Z","shell.execute_reply.started":"2023-09-22T10:42:20.149389Z","shell.execute_reply":"2023-09-22T10:42:20.203057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get number distinct values in ocean_proximity\nprint(housing[\"ocean_proximity\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:20.206213Z","iopub.execute_input":"2023-09-22T10:42:20.206700Z","iopub.status.idle":"2023-09-22T10:42:20.216664Z","shell.execute_reply.started":"2023-09-22T10:42:20.206670Z","shell.execute_reply":"2023-09-22T10:42:20.215451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show the histograom of all the numeric columns\nhousing.hist(bins=50,figsize=(12,8))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:20.218841Z","iopub.execute_input":"2023-09-22T10:42:20.219585Z","iopub.status.idle":"2023-09-22T10:42:22.827499Z","shell.execute_reply.started":"2023-09-22T10:42:20.219552Z","shell.execute_reply":"2023-09-22T10:42:22.826227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#look for correlations, note only numeric columns shold be selected\ncorr_matrix = housing.select_dtypes(include='number').corr()\nprint(corr_matrix[\"median_house_value\"].sort_values(ascending=False))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:22.829838Z","iopub.execute_input":"2023-09-22T10:42:22.830219Z","iopub.status.idle":"2023-09-22T10:42:22.846068Z","shell.execute_reply.started":"2023-09-22T10:42:22.830186Z","shell.execute_reply":"2023-09-22T10:42:22.844758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create scatter matrix\nattributes = [\"median_house_value\",\"median_income\",\"total_rooms\",\"housing_median_age\"]\nscatter_matrix(housing[attributes], figsize=(12,8))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:22.847543Z","iopub.execute_input":"2023-09-22T10:42:22.847933Z","iopub.status.idle":"2023-09-22T10:42:25.606272Z","shell.execute_reply.started":"2023-09-22T10:42:22.847902Z","shell.execute_reply":"2023-09-22T10:42:25.605100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check median house value per ocean proximity category\ndf1 = housing.groupby(\"ocean_proximity\")[[\"median_house_value\"]].agg([\"mean\",\"median\",\"count\"])\nprint(df1)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:25.609282Z","iopub.execute_input":"2023-09-22T10:42:25.610348Z","iopub.status.idle":"2023-09-22T10:42:25.631589Z","shell.execute_reply.started":"2023-09-22T10:42:25.610295Z","shell.execute_reply":"2023-09-22T10:42:25.630156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create scatter plot showing relation of house value with color and population with size with longitude and latitude\nhousing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", grid=True, \n             s=housing[\"population\"]/100, label=\"ppoplulation\", \n             c=\"median_house_value\", cmap=\"jet\", colorbar=True,\n            legend=True, sharex=False, figsize=(10,7))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:25.633998Z","iopub.execute_input":"2023-09-22T10:42:25.634376Z","iopub.status.idle":"2023-09-22T10:42:26.617309Z","shell.execute_reply.started":"2023-09-22T10:42:25.634345Z","shell.execute_reply":"2023-09-22T10:42:26.615763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Strtified train and test set based on median_income\n**Then drop the median cat column**","metadata":{}},{"cell_type":"code","source":"#create new column with pd.cut creating bins for income category\nhousing[\"income_cat\"]=pd.cut(housing[\"median_income\"], bins=[0.,1.5, 3.0, 4.5, 6., np.inf], labels=[1,2,3,4,5])","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:26.619299Z","iopub.execute_input":"2023-09-22T10:42:26.619678Z","iopub.status.idle":"2023-09-22T10:42:26.629381Z","shell.execute_reply.started":"2023-09-22T10:42:26.619645Z","shell.execute_reply":"2023-09-22T10:42:26.628039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train test split\ntrain_set, test_set = train_test_split(housing, test_size=0.2, stratify=housing[\"income_cat\"], random_state=42)\ntrain_set.drop(\"income_cat\", axis=1, inplace=True)\ntest_set.drop(\"income_cat\", axis=1, inplace=True)\nhousing.drop(\"income_cat\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:26.630842Z","iopub.execute_input":"2023-09-22T10:42:26.631193Z","iopub.status.idle":"2023-09-22T10:42:26.663746Z","shell.execute_reply.started":"2023-09-22T10:42:26.631163Z","shell.execute_reply":"2023-09-22T10:42:26.662441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of raw dataset is {}\".format(housing.shape))\nprint(\"Shape of train_set dataset is {}\".format(train_set.shape))\nprint(\"Shape of test_set dataset is {}\".format(test_set.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:26.665229Z","iopub.execute_input":"2023-09-22T10:42:26.665550Z","iopub.status.idle":"2023-09-22T10:42:26.672723Z","shell.execute_reply.started":"2023-09-22T10:42:26.665521Z","shell.execute_reply":"2023-09-22T10:42:26.671333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Prepare data for model**","metadata":{}},{"cell_type":"code","source":"#divide train and test sets into inputs and labels\ntrain_inputs = train_set.drop(\"median_house_value\", axis=1)\ntrain_labels = train_set[\"median_house_value\"].copy()\n\ntest_inputs = test_set.drop(\"median_house_value\", axis=1)\ntest_labels = test_set[\"median_house_value\"].copy()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:26.674713Z","iopub.execute_input":"2023-09-22T10:42:26.675113Z","iopub.status.idle":"2023-09-22T10:42:26.689570Z","shell.execute_reply.started":"2023-09-22T10:42:26.675065Z","shell.execute_reply":"2023-09-22T10:42:26.688243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Below is the Simple pipeline which preprocesses both numeric and categorical columns\n# For a custom and more complex preprocessing refer below","metadata":{}},{"cell_type":"code","source":"#Column transformer to preprocess both numeric and categorical data\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_attribs = [\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"]\ncat_attribs = [\"ocean_proximity\"]\n\nnum_pipeline = make_pipeline(\n    SimpleImputer(strategy=\"median\"),\n    StandardScaler())\n\ncat_pipeline = make_pipeline(\n    SimpleImputer(strategy=\"most_frequent\"),\n    OneHotEncoder(handle_unknown=\"ignore\"))\n\npreprocessing_simple = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", cat_pipeline, cat_attribs)\n])\n\n\n#alternatively preprocessing can automatically be created by just referring to numeric and categorical columns\n'''\nfrom sklearn.compose import make_column_selector, make_column_transformer\n\npreprocessing = make_column_transformer(\n    (num_pipeline, make_column_selector(dtype_include=np.number)),\n    (cat_pipeline, make_column_selector(dtype_include=object)),\n)\n'''\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:26.694561Z","iopub.execute_input":"2023-09-22T10:42:26.694975Z","iopub.status.idle":"2023-09-22T10:42:26.708050Z","shell.execute_reply.started":"2023-09-22T10:42:26.694943Z","shell.execute_reply":"2023-09-22T10:42:26.706842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A more complex pre-processing with ratio of columns and cluster similarity","metadata":{}},{"cell_type":"code","source":"#Write custom class to detect Cluster Similarity\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics.pairwise import rbf_kernel\n\nclass ClusterSimilarity(BaseEstimator, TransformerMixin):\n    def __init__(self, n_clusters=10, n_init=10,  gamma=1.0, random_state=None):\n        self.n_clusters = n_clusters\n        self.gamma = gamma\n        self.random_state = random_state\n        self.n_init = n_init\n    \n    def fit(self, X, y=None, sample_weight=None):\n        self.kmeans_ = KMeans(self.n_clusters, random_state=self.random_state, n_init=self.n_init)\n        self.kmeans_.fit(X,sample_weight=sample_weight)\n        return self #always return self\n    def transform(self, X):\n        return rbf_kernel(X, self.kmeans_.cluster_centers_, gamma=self.gamma)\n    \n    def get_feature_names_out(self, names=None):\n        return [f\"Cluster {i} similarity\"for i in range(self.n_clusters)]\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:26.709504Z","iopub.execute_input":"2023-09-22T10:42:26.709889Z","iopub.status.idle":"2023-09-22T10:42:26.722674Z","shell.execute_reply.started":"2023-09-22T10:42:26.709856Z","shell.execute_reply":"2023-09-22T10:42:26.721359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#custom functions for ratio pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import ColumnTransformer\n\ndef column_ratio(X):\n    return X[:,[0]]/X[:,[1]]\n\ndef ratio_name(function_transformer, feature_names_in):\n    return [\"ratio\"] #feature names out\n\ndef ratio_pipeline():\n    return make_pipeline(\n        SimpleImputer(strategy=\"median\"),\n        FunctionTransformer(column_ratio, feature_names_out = ratio_name),\n        StandardScaler())\n\n#log pipeline \n\nlog_pipeline = make_pipeline(\n    SimpleImputer(strategy=\"median\"),\n    FunctionTransformer(np.log, feature_names_out = \"one-to-one\"),\n    StandardScaler())\n\n#cluster_simil\ncluster_simil = ClusterSimilarity(n_clusters=10, n_init=10, gamma=1., random_state=42)\n\ndefault_num_pipeline = make_pipeline(\n    SimpleImputer(strategy=\"median\"),\n    StandardScaler())\n\ncat_pipeline = make_pipeline(\n    SimpleImputer(strategy=\"most_frequent\"),\n    OneHotEncoder(handle_unknown=\"ignore\"))\n\npreprocessing_complex = ColumnTransformer([\n    (\"bedrooms\", ratio_pipeline(), [\"total_bedrooms\", \"total_rooms\"]),\n    (\"rooms_per_house\", ratio_pipeline(), [\"total_rooms\",\"households\"]),\n    (\"people_per_house\", ratio_pipeline(), [\"population\",\"households\"]),\n    (\"log\", log_pipeline, [\"total_bedrooms\", \"total_rooms\",\"population\",\"households\",\"median_income\"]),\n    (\"geo\", cluster_simil, [\"latitude\", \"longitude\"]),\n    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object)),\n    \n],\nremainder = default_num_pipeline)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:26.724742Z","iopub.execute_input":"2023-09-22T10:42:26.725245Z","iopub.status.idle":"2023-09-22T10:42:26.743407Z","shell.execute_reply.started":"2023-09-22T10:42:26.725202Z","shell.execute_reply":"2023-09-22T10:42:26.742290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# By any of the above two preprocessing sections you have developed a pipeline to pre-process data\n# Lets transform the data now","metadata":{}},{"cell_type":"code","source":"#prepare trining data\ntrain_inputs_prepared = preprocessing_complex.fit_transform(train_inputs)\n\nprint(train_inputs_prepared.shape)\npreprocessing_complex.get_feature_names_out()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:26.745327Z","iopub.execute_input":"2023-09-22T10:42:26.745760Z","iopub.status.idle":"2023-09-22T10:42:28.123439Z","shell.execute_reply.started":"2023-09-22T10:42:26.745719Z","shell.execute_reply":"2023-09-22T10:42:28.121868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now its time to Select and Train Random Forest Model","metadata":{}},{"cell_type":"code","source":"#train random forest regressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import make_pipeline\n\nforest_reg = make_pipeline(preprocessing_complex, RandomForestRegressor(random_state=42))\nforest_reg.fit(train_inputs, train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:28.131806Z","iopub.execute_input":"2023-09-22T10:42:28.136481Z","iopub.status.idle":"2023-09-22T10:42:59.921997Z","shell.execute_reply.started":"2023-09-22T10:42:28.136404Z","shell.execute_reply":"2023-09-22T10:42:59.920742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use cross validation for evaluation\nfrom sklearn.model_selection import cross_val_score\n\nforest_reg = -cross_val_score(forest_reg, train_inputs, train_labels, scoring=\"neg_root_mean_squared_error\",cv=3)\npd.Series(forest_reg).describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:42:59.923579Z","iopub.execute_input":"2023-09-22T10:42:59.924041Z","iopub.status.idle":"2023-09-22T10:44:03.277218Z","shell.execute_reply.started":"2023-09-22T10:42:59.924001Z","shell.execute_reply":"2023-09-22T10:44:03.275946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Grid Search CV to find optimal parameters","metadata":{}},{"cell_type":"code","source":"#use grid search cv\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\n\nfull_pipeline = Pipeline([\n    (\"preprocessing\", preprocessing_complex),\n    (\"random_forest\", RandomForestRegressor(random_state=42)),\n])\n\nparam_grid = [\n    {'preprocessing__geo__n_clusters': [5,8,10],\n     'random_forest__max_features': [4, 6, 8],},\n    \n    {'preprocessing__geo__n_clusters': [10,15],\n     'random_forest__max_features': [6, 8, 10],},\n]\n\ngrid_search = GridSearchCV(full_pipeline, param_grid, cv=3, scoring=\"neg_root_mean_squared_error\")\ngrid_search.fit(train_inputs, train_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:44:03.280162Z","iopub.execute_input":"2023-09-22T10:44:03.280653Z","iopub.status.idle":"2023-09-22T10:49:53.669632Z","shell.execute_reply.started":"2023-09-22T10:44:03.280612Z","shell.execute_reply":"2023-09-22T10:49:53.668344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get best parameters from grid_search_cv\nprint(\"Printing out Best Prameters\")\nprint(grid_search.best_params_)\n\n\n#get top results\ncv_res = pd.DataFrame(grid_search.cv_results_)\ncv_res.sort_values(by=\"mean_test_score\",ascending=False, inplace=True)\nprint(\"Printing Top Results from Cross Validation\")\nprint(cv_res.head())\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:49:53.671189Z","iopub.execute_input":"2023-09-22T10:49:53.671549Z","iopub.status.idle":"2023-09-22T10:49:53.690025Z","shell.execute_reply.started":"2023-09-22T10:49:53.671518Z","shell.execute_reply":"2023-09-22T10:49:53.688312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use Random Search to find Best Parameters","metadata":{}},{"cell_type":"code","source":"#using random search \nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\nfrom sklearn.pipeline import Pipeline\n\nfull_pipeline = Pipeline([\n    (\"preprocessing\", preprocessing_complex),\n    (\"random_forest\", RandomForestRegressor(random_state=42)),\n])\n\nparam_distribs = {'preprocessing__geo__n_clusters': randint(low=3, high=50),\n                  'random_forest__max_features': randint(low=2, high=20)}\n\nrnd_search = RandomizedSearchCV(\n    full_pipeline, param_distributions = param_distribs, n_iter = 10, cv=3,\n    scoring = \"neg_root_mean_squared_error\", random_state=42)\n\nrnd_search.fit(train_inputs, train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:49:53.691455Z","iopub.execute_input":"2023-09-22T10:49:53.691815Z","iopub.status.idle":"2023-09-22T10:54:31.444877Z","shell.execute_reply.started":"2023-09-22T10:49:53.691771Z","shell.execute_reply":"2023-09-22T10:54:31.443954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get best model from random serarch\nfinal_model = rnd_search.best_estimator_\n\n#get important features\nfeature_importance = final_model[\"random_forest\"].feature_importances_\nfeature_names = final_model[\"preprocessing\"].get_feature_names_out()\nprint(sorted(zip(feature_importance, feature_names),reverse=True))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:54:31.446338Z","iopub.execute_input":"2023-09-22T10:54:31.446953Z","iopub.status.idle":"2023-09-22T10:54:31.490504Z","shell.execute_reply.started":"2023-09-22T10:54:31.446913Z","shell.execute_reply":"2023-09-22T10:54:31.489020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict on Test Set from the best model from random search ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nfinal_predictions = final_model.predict(test_inputs)\n\nfinal_rmse = mean_squared_error(test_labels, final_predictions, squared=False)\nprint(\"Final RMSE is %.0f\" %(final_rmse))\n\nprint(\"\")\nprint(\"Final Predictions are\")\nprint(final_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:54:31.492106Z","iopub.execute_input":"2023-09-22T10:54:31.492636Z","iopub.status.idle":"2023-09-22T10:54:31.726320Z","shell.execute_reply.started":"2023-09-22T10:54:31.492596Z","shell.execute_reply":"2023-09-22T10:54:31.725003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate 95% Confidence Interval","metadata":{}},{"cell_type":"code","source":"#get 95% confidence interval\nfrom scipy import stats\nconfidence = 0.95\n\nsquared_errors = (final_predictions - test_labels) ** 2\nconfidence_range = np.sqrt(stats.t.interval(confidence, len(squared_errors)-1,\n                        loc=squared_errors.mean(),\n                        scale=stats.sem(squared_errors)))\n\nprint(\"95% Confidence Range is {}\".format(confidence_range))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:54:31.727853Z","iopub.execute_input":"2023-09-22T10:54:31.728658Z","iopub.status.idle":"2023-09-22T10:54:31.741045Z","shell.execute_reply.started":"2023-09-22T10:54:31.728623Z","shell.execute_reply":"2023-09-22T10:54:31.739859Z"},"trusted":true},"execution_count":null,"outputs":[]}]}